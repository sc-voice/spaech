#!/usr/bin/env node

const fs = require('fs');
const path = require('path');
const assert = require('assert')
const { exec, execSync } = require('child_process');
const { logger } = require('log-instance');
const { WaveFile } = require('wavefile');

// avoid Tensorflow include via ../index
const Chart = require('../src/chart');
const Synthesizer = require('../src/synthesizer');
const Signal = require('../src/signal');
const YinPitch = require('../src/yin-pitch');

const APP_DIR = path.dirname(__dirname);
const TEST_DATA_DIR = path.join(APP_DIR, 'test/data');
const EVAM_ME_SUTTAM_WAV = path.join(TEST_DATA_DIR, 'evam-me-suttam.wav');
const AN9_20_4_3_WAV = path.join(TEST_DATA_DIR, 'an9.20_4.3.wav');
const argv = process.argv;
const script = argv[1].split('/').pop();
const SOUND_END = path.join(APP_DIR, 'static/training-end.mp3');
const SOUND_SUCCESS = path.join(APP_DIR, 'static/training-success.mp3');
const SOUND_FAILURE = path.join(APP_DIR, 'static/training-failure.mp3');
const SOUND_ADJUST = path.join(APP_DIR, 'static/training-adjust.mp3');

function help() {
    console.log(`
NAME
        formants - audio formant analyser

SYNOPSIS
        formants [OPTIONS] 
        formants -si INPUT_WAV 

DESCRIPTION
        Speech formant analyser detects F0, F1, F2 for given WAV signal.

    -cl, --chart-lines N
        Number of lines used to chart worst signal mismatch (15)

    -?, --help
        Print help

    -ad, --acf-diff
        Maximum ACF difference threshold (0.1);

    -fb, --frequency-band FMIN FMAX
        Minimum and maximium speech frequencies recognized (85 300).
        Male speech is in the 85-150Hz band.  Female speech is in the 160-255Hz band.
        Child speech is at 300 Hz.

    -fs, --frame-size
        Input is broken up into frames.

    -ha, --harmonic-amplitude
        Minimum harmonic amplitude to be recognized as a harmonic (1)

    -hc, --harmonics-count
        Number of harmonics (21)
        
    -ho, --harmonic-output WAV_FILE
        Harmonic resonator WAV signal

    -hs, --half-life-samples
        Number of samples for zero-input signal half-life decay (8)

    -ll, --log-level
        Logging level: warn, error, [info], debug

    -mp, --min-power
        Minimum signal power for pitch recognition (128)

    -rc, --resonator-count COUNT
        Count of resonators in harmonic waveform synthesizer (20)

    -ro, --residual-out WAV_FILE
        Residual non-harmonic output file

    -si, --signal-in WAV_FILE
        Input signal 

    -sk, --skew NSAMPLES
        Advance output by given number of samples (0)

    -vb, --verbose
        Verbose output

    -vf, --verbose-frames F1 FN
        Provide verbose information for frames [F1,FN] 

    -wi, --window
        Auto-correlation window size (551)
`);
    process.exit(0);
}

function playSound(sound) {
  let cmd = `ffplay -nodisp -autoexit -loglevel error -stats ${sound}`;
  execSync(cmd, {
    cwd: APP_DIR,
  });
}

function die(e) {
  playSound(SOUND_FAILURE);
  process.exit(-1);
}

var cmdCfg = {};

var nargs = argv.length;
if (nargs < 3) {
    help();
}
for (var i = 2; i < nargs; i++) {
  var arg = argv[i];
  let requiredArg = (key=arg)=>{
    let nextArg = argv[++i];
    if (nextArg == null) {
      die(logger.error('E_REQUIRED', `Expected additional information for: ${key}`));
    }
    return nextArg;
  }
  let requiredNumber = (key=arg)=>{
    let n = Number(requiredArg());
    if (isNaN(n)) {
      die(logger.error(`[E_NUMBER] "${key}" option requires a number:${argv[i]}`));
    }
    return n;
  }
  if (i<2) { continue; }
  if (arg === '-?' || arg === '--help') {
    help();
    cmdCfg.signalExpected = requiredArg();
  } else if (arg === '-ad' || arg === '--acf-diff') {
    cmdCfg.diffMax = requiredNumber();
  } else if (arg === '-fb' || arg === '--frequency-band') {
    cmdCfg.fMin = requiredNumber(arg);
    cmdCfg.fMax = requiredNumber(arg);
  } else if (arg === '-fs' || arg === '--frame-size') {
    cmdCfg.frameSize = requiredNumber();
  } else if (arg === '-ha' || arg === '--harmonic-amplitude') {
    cmdCfg.minAmplitude = requiredNumber();
  } else if (arg === '-ho' || arg === '--harmonic-out') {
    cmdCfg.harmonicOut = requiredArg();
  } else if (arg === '-hs' || arg === '--half-life-samples') {
    cmdCfg.halfLifeSamples = requiredNumber();
  } else if (arg === '-mp' || arg === '--min-power') {
    cmdCfg.minPower = requiredNumber();
  } else if (arg === '-si' || arg === '--signal-in') {
    cmdCfg.signalIn = requiredArg();
  } else if (arg === '-ll' || arg === '--log-level') {
    cmdCfg.logLevel = logger.logLevel = requiredArg();
  } else if (arg === '-sa' || arg === '--sample') {
    cmdCfg.sample = true;
  } else if (arg === '-hc' || arg === '--harmonics-count') {
    cmdCfg.nHarmonics = requiredNumber();
  } else if (arg === '-rc' || arg === '--resonator-count') {
    cmdCfg.resonatorCount = requiredNumber();
  } else if (arg === '-ro' || arg === '--residual-out') {
    cmdCfg.residualOut = requiredArg();
  } else if (arg === '-sk' || arg === '--skew') {
    cmdCfg.skew = requiredNumber();
  } else if (arg === '-vb' || arg === '--verbose') {
    cmdCfg.verbose = true;
  } else if (arg === '-vf' || arg === '--verbose-frames') {
    cmdCfg.verboseFrame1 = requiredNumber(arg);
    cmdCfg.verboseFrameN = requiredNumber(arg);
  } else if (arg === '-wi' || arg === '--window') {
    cmdCfg.window = requiredNumber();
  } else {
    die(logger.error('E_UNKNOWN_OPTION', `Unknown option: ${argv[i]}`));
  }
}

async function wavSignal(fpath) {
  assert(fpath, `Expected signal file path: ${fpath}`);
  let buf = await fs.promises.readFile(fpath);
  let wf = new WaveFile(buf);
  //let wavSig = new Signal(wf.getSamples(false, Int16Array));
  let wavSig = Signal.fromWav(buf);
  let { sampleRate } = wavSig;
  let stats = wavSig.stats();
  logger.debug(`wavSignal`, fpath, stats);
  logger.info(`wavSignal() ${fpath} =>`, `max:`, stats.max, `count:`, stats.count,
    `sampleRate:`, sampleRate);

  return wavSig;
}

async function configuration(cfg=cmdCfg) {
  let { 
    harmonicOut,
    signalIn, 
  } = cfg;

  assert(fs.existsSync(signalIn), `[E_SIGNAL_IN] file not found:${signalIn}`);

  return Object.assign({}, {
    chartLines: 15,
    diffMax: 0.1,
    fMin: 85,
    fMax: 300,
    halfLifeSamples: 8,
    harmonicOut,
    frameSize: 96,
    logLevel: 'info',
    minAmplitude: 1,
    minPower: 1,
    nHarmonics: 21,
    sample: false,
    resonatorCount: 20,
    skew: 0,
    signalIn,
    verbose: false,
    window: 551,

  }, cfg, {
  });
}

async function writeSignal(fpath, signal) {
  if (fpath.endsWith('.wav')) {
    let wav = signal.toWav();
    try {
      await fs.promises.writeFile(fpath, wav);
      logger.info(`writing signal: ${fpath} length: ${wav.length}`);
    } catch(e) {
      die(logger.error(`Could not write: ${fpath}`, e.message));
    }
  } else {
    die(logger.error('E_FILE_UNSUPPORTED', `Unsupported file type: ${fpath}`));
  }
}

function inputsOfFrames(frames, inputSize) {
  let frameSize = frames[0].length;
  let wavFrames = Math.ceil(inputSize / frameSize);
  let iEnd = frames.length - 1;
  let inputs = frames.map((f,i) => {
    let inputRow = [];
    for (let j=i; j < i+wavFrames; j++) {
      let fj = frames[j] || new Float32Array(frameSize);
      inputRow = inputRow.concat([...fj]);
    }
    return inputRow;
  });
  return inputs;
}

(async function() {
  let cfg = await configuration(cmdCfg);
  let msStart = Date.now();
  let { 
    chartLines,
    diffMax,
    fMin,
    fMax,
    frameSize,
    halfLifeSamples,
    harmonicOut,
    minAmplitude,
    minPower,
    nHarmonics,
    sample,
    residualOut,
    resonatorCount,
    signalIn, 
    skew,
    verbose,
    verboseFrame1,
    verboseFrameN,
    window,

  } = cfg;
  let resBank = new Synthesizer({
    length: resonatorCount, 
    frameSize,
    halfLifeSamples,
  });
  let dataHarmonic = [];
  logger.info(script, argv.slice(2).join(' '));
  verbose && logger.info(`command options parsed as`, cfg);

  let sigIn = await wavSignal(signalIn);
  let { data:dataIn, sampleRate } = sigIn;
  let yp = new YinPitch({
    sampleRate, diffMax, fMin, fMax, window, minAmplitude, minPower,
  });
  let nSamples = Math.ceil(yp.minSamples / frameSize) * frameSize;
  logger.info({nSamples, dataIn:dataIn.length});
  let chart = new Chart({lines:chartLines});
  let resBankFun = (a1,a2)=>resBank.sample(a1,a2);

  for (let i = 0; i < dataIn.length; i += frameSize) {
    let iFrame = i/frameSize;
    let verbosePrefix = `frame:${i/frameSize} [${i}] t:${(i/sampleRate).toFixed(3)}`;
    let verboseFrame = verboseFrame1 <= iFrame && iFrame <= verboseFrameN;
    let samples = dataIn.subarray(i, i+nSamples);
    if (samples.length === nSamples) {
      let harmonics;
      try {
        harmonics = yp.harmonics(samples, {nHarmonics});
        dataHarmonic = dataHarmonic.concat(resBankFun(harmonics));
      } catch (e) {
        let ferr = path.join(__dirname, '../local/error.json');
        await fs.promises.writeFile(ferr, JSON.stringify({
          e: e.message, samples:[...samples], iFrame, frameSize, i, }));
        logger.warn(`${verbosePrefix} Caught exception ${e.message}`);
        throw e;
      }
      if (harmonics.length) {
        let {frequency:f0, amplitude:a0} = harmonics[0];
        let { pitch } = yp.pitch(samples);
        verboseFrame && console.log(verbosePrefix, 
          `${f0.toFixed(1)}Hz`, 
          harmonics
            .sort((a,b)=>b.amplitude-a.amplitude)
            .map(h=>`h${h.order}:${h.amplitude.toFixed(0)}`)
            .join(', '));
      } else {
        verboseFrame && console.log(verbosePrefix);
      }
    } else {
      logger.debug(`discarding partial samples[${i}]:${samples.length}`);
    }
  }

  let elapsed = ((Date.now()-msStart)/60000).toFixed(1);
  if (harmonicOut) {
    let tail = resBankFun([], {nSamples:skew + dataIn.length - dataHarmonic.length});
    dataHarmonic = [...dataHarmonic.slice(skew), ...tail];
    let sigHarmonic = new Signal(dataHarmonic);
    await writeSignal(harmonicOut, sigHarmonic);
    let mse = Signal.rmsErr(dataIn, dataHarmonic);
    logger.info(`harmonicOut => ${harmonicOut}`,
      `dataIn:${dataIn.length}`,
      `dataHarmonic:${dataHarmonic.length}`,
      `mse:${mse}`);
    await playSound(harmonicOut);
    if (verboseFrame1 != null) {
      let f1 = verboseFrame1 * frameSize;
      let fEnd = (verboseFrameN + 1) * frameSize;
      chart.plot({
        title:`frames:[${verboseFrame1},${verboseFrameN}] 1:dataIn 2:dataHarmonic`,
        data:[
          dataIn.slice(f1,fEnd), 
          dataHarmonic.slice(f1,fEnd),
        ],
        lineLength: frameSize,
      });
    }
  }

  if (residualOut) {
    assert(harmonicOut, `[E_RESIDUAL_HARMONIC] no harmonic output for residual`);
    let dataResidual = [];
    for (let i = 0; i < dataHarmonic.length; i++) {
      let v = dataIn[i] - dataHarmonic[i];
      dataResidual.push(v);
    }
    await writeSignal(residualOut, new Signal(dataResidual));
    await playSound(residualOut);
  }

  process.exit(0);
})();
