#!/usr/bin/env node

const fs = require('fs');
const path = require('path');
const assert = require('assert')
const { logger } = require('log-instance');
const tf = require('@tensorflow/tfjs-node');
const { WaveFile } = require('wavefile');
const {
  Chart,
  AutoEncoder,
  Mdct,
  Signal,
} = require('../index');

function help() {
    console.log(`
NAME
        mdct3-coder - compress/expand MDCT tri-blocks to audio

SYNOPSIS
        mdct3-coder [OPTIONS] 
        mdct3-coder --signal-in TRAIN_WAV --model-path MODEL_PATH --train
        mdct3-coder --signal-in SRC_WAV --model-path MODEL_PATH --signal-out DST_WAV

DESCRIPTION
        Autoencode audio signal with an asymmetric auto-encoder (AAN). AAN input
        consists of tri-blocks of 3*frameSize/2 MDCT coefficients. AAN output
        consists of audio signal frames with a default frameSize of 192.
        The AAN relies on snake activations (https://arxiv.org/pdf/2006.08195.pdf)
        to handle the periodicity inherent in audio signals.

        The MDCT3 auto-encoder is asymmetric, with 3 inputs for every 2 outputs.  
        This 3:2 ratio characterizes the MDCT coefficient overlap
        in that it takes 3 coefficient blocks to represent a single signal frame
        that is the length of 2 coefficient blocks. The asymmetry allows
        the auto-encoder to use MDCT coefficient tri-blocks as recognizable features.
        Each tri-block has a 1-to-1 mapping to the corresponding audio frame, so
        the autoencoder is essentially still doing a 1-to-1 mapping, but from a
        pre-transformed input space.

    -bs, --batch-size N
        Number of training examples in each batch (128)

    -cl, --chart-lines N
        Number of lines used to chart worst signal mismatch (15)

    -cs, --code-size
        Number of units in the bottleneck code layer.

    -dl, --decoder-layers N
        Number of decoder layers (encoderLayers)

    -du, --decoder-units N1,N2,...,NN
        Number of units in each decoder layer: (reverse of encoderUnits)

    -ea, --encoder-alpha A
    -ea, --encoder-alpha A1,A2,...,AN 
        Snake activation frequency coefficient. Either a list of alpha
        coefficients (one for each layer), or a single number. A single
        alpha number will be used to generate an alpha for each
        encoder/decoder layer. The default is the Golden Ratio.

    -el, --encoder-layers N
        Number of encoder/decoder layers (3)

    -ep, --epochs
        Training epochs (100)

    -eu, --encoder-units K
    -eu, --encoder-units N1,N2,...,NN
        Number of units in each encoder layer (0.8)
        If a single number K is given, the each successive layer will decrease
        by given factor (e.g., frameSize, K*frameSize, K*K*frameSize, ...)
        Alternatively, a list of specific unit numbers can be given.

    -ie, --initial-epoch EPOCH
        Initial epoch for continued training

    -le, --log-epoch N
        Log training stats every every N epochs (10)

    -fs, --frame-size
        Audio is encoded/decoded by consecutive frames of given size. (192)

    -?, --help
        Print help

    -ll, --log-level
        Logging level: warn, error, [info], debug

    -ms, --mdct-stats JSON_FILE
        Save MDCT coefficient stats for input signal

    -mp, --model-path MODEL_FOLDER
    -mp, --model-path URL
        JSON resource URL or local file path (test/model/coder)

    -ns, --no-shuffle
        Do not shuffle training dataset (shuffle)

    -ro, --residual-out WAV_FILE
        Output residual of signal minus tranformed signal.
        
    -scm, --scale-mdct SCALE
    -scm, --scale-mdct JSON_FILE
        MDCT coefficient normalization to [-1,1] interval. (512)
        If a JSON file is given, the scale array is read from the file.

    -sc, --scale SCALE
        Output audio signal scale (16384)

    -si, --signal-in WAV_FILE
        Input signal

    -so, --signal-out WAV_FILE
        Output signal

    -ta, --train-attempts N
        Train code with up to N attempts to save a better model (1)

    -tr, --train  
        Train coder using input signal
`);
    process.exit(0);
}

const TEST_DATA_DIR = path.join(path.dirname(__dirname), 'test/data');
const EVAM_ME_SUTTAM_WAV = path.join(TEST_DATA_DIR, 'evam-me-suttam.wav');
const AN9_20_4_3_WAV = path.join(TEST_DATA_DIR, 'an9.20_4.3.wav');
const argv = process.argv;
const script = argv[1].split('/').pop();

var cmdCfg = {};

var nargs = argv.length;
if (nargs < 3) {
    help();
}
for (var i = 2; i < nargs; i++) {
  var arg = argv[i];
  let requiredArg = ()=>{
    let nextArg = argv[++i];
    if (nextArg == null) {
      throw logger.error('E_REQUIRED', `Expected additional information for: ${arg}`);
    }
    return nextArg;
  }
  let requiredNumber = ()=>{
    let n = Number(requiredArg());
    if (isNaN(n)) {
      throw logger.error(`[E_NUMBER] "${argv[i-1]}" option requires a number:${argv[i]}`);
    }
    return n;
  }
  if (i<2) { continue; }
  if (arg === '-?' || arg === '--help') {
    help();
  } else if (arg === '-du' || arg === '--decoder-units') {
    cmdCfg.decoderUnits = requiredArg().split(',').map(v=>Math.max(1, Math.round(Number(v))));
  } else if (arg === '-ea' || arg === '--encoder-alpha') {
    cmdCfg.encoderAlpha = requiredArg().split(',').map(v=>Number(v));
    if (cmdCfg.encoderAlpha.length === 1) { cmdCfg.encoderAlpha = cmdCfg.encoderAlpha[0]; }
  } else if (arg === '-le' || arg === '--log-epoch') {
    cmdCfg.logEpoch = requiredNumber();
  } else if (arg === '-dl' || arg === '--decoder-layers') {
    cmdCfg.decoderLayers = requiredNumber();
  } else if (arg === '-el' || arg === '--encoder-layers') {
    cmdCfg.encoderLayers = requiredNumber();
  } else if (arg === '-eu' || arg === '--encoder-units') {
    cmdCfg.encoderUnits = requiredArg();
  } else if (arg === '-scm' || arg === '--scale-mdct') {
    cmdCfg.scaleIn = requiredArg();
  } else if (arg === '-sc' || arg === '--scale') {
    cmdCfg.scaleOut = requiredNumber();
  } else if (arg === '-ns' || arg === '--no-shuffle') {
    cmdCfg.shuffle = false;
  } else if (arg === '-ep' || arg === '--epochs') {
    cmdCfg.epochs = requiredNumber();
  } else if (arg === '-ie' || arg === '--initial-epoch') {
    cmdCfg.initialEpoch = requiredNumber();
  } else if (arg === '-ms' || arg === '--mdct-stats') {
    cmdCfg.mdctStatsPath = requiredArg();
  } else if (arg === '-mp' || arg === '--model-path') {
    cmdCfg.modelPath = requiredArg();
  } else if (arg === '-bs' || arg === '--batch-size') {
    cmdCfg.batchSize = requiredNumber();
  } else if (arg === '-cl' || arg === '--chart-lines') {
    cmdCfg.chartLines = requiredNumber();
  } else if (arg === '-ta' || arg === '--train-attempts') {
    cmdCfg.trainAttempts = requiredNumber();
  } else if (arg === '-cs' || arg === '--code-size') {
    cmdCfg.codeSize = requiredNumber();
  } else if (arg === '-na' || arg === '--noise-amplitude') {
    cmdCfg.noiseAmplitude = requiredNumber();
  } else if (arg === '-fs' || arg === '--frame-size') {
    cmdCfg.frameSize = requiredNumber();
  } else if (arg === '-ro' || arg === '--residual-out') {
    cmdCfg.residualOut = requiredArg();
  } else if (arg === '-si' || arg === '--signal-in') {
    cmdCfg.signalIn = requiredArg();
  } else if (arg === '-so' || arg === '--signal-out') {
    cmdCfg.signalOut = requiredArg();
  } else if (arg === '-tr' || arg === '--train') {
    cmdCfg.trainModel = true;
  } else if (arg === '-ll' || arg === '--log-level') {
    cmdCfg.logLevel = logger.logLevel = requiredArg();
  } else {
    throw logger.error('E_UNKNOWN_OPTION', `Unknown option: ${argv[i]}`);
  }
}

async function wavSignal(fpath=EVAM_ME_SUTTAM_WAV) {
  assert(fpath, `Expected signal file path`);
  let buf = await fs.promises.readFile(fpath);
  let wf = new WaveFile(buf);
  let wavSig = new Signal(wf.getSamples(false, Int16Array));
  let stats = wavSig.stats();
  logger.debug(`wavSignal`, fpath, stats);
  logger.info(`wavSignal() ${fpath} =>`, `max: ${stats.max}`, `count: ${stats.count}`);

  return wavSig;
}

async function mdctTriBlocks({wavSig, mdct, scaleIn}) {
  let { frameSize } = mdct;
  assert(wavSig, `Expected input WAV signal`);
  assert(scaleIn instanceof Array, `Expected scaleIn array`);
  let {data:sigIn} = wavSig;
  let window = Mdct.WINDOWS[1];
  let triBks = [...mdct.encodeTriBlocks(sigIn, {})];
  let maxScaled = 0;
  let inputs = triBks.map(tb=>tb.map((v,i)=>{
    let vScaled = v/scaleIn[i];
    if (maxScaled < vScaled) { maxScaled = vScaled }
    return vScaled;
  }));
  logger.info(`mdctTriBlocks() tri-blocks: ${triBks.length}, maxScaled: ${maxScaled}`); 
  return {triBks, inputs};
}

function normalizeUrl(urlOrPath) {
  if (urlOrPath == null) {
    throw logger.error('E_MODEL_PATH', `Model url or path is required: -mp PATH`);
  }
  if (/^[a-z]*:/.test(urlOrPath)) {
    return urlOrPath;
  } 

  var url = path.join(process.cwd(), urlOrPath);
  return `file:////${url}`;
}

async function configuration(cfg=cmdCfg) {
  let { encoderUnits, decoderLayers, frameSize=192, scaleIn, scaleOut=16384 } = cfg;

  if (encoderUnits != null) {
    if (/,/.test(encoderUnits)) {
      encoderUnits = encoderUnits.split(',').map(v=>Math.round(Number(v)));
    } else {
      encoderUnits = Number(encoderUnits);
    }
  }

  let inputSize = frameSize * 3 / 2;
  let outputSize = frameSize;
  scaleIn = await initializeScale(scaleIn);

  return Object.assign({}, {
    batchSize: 128,
    chartLines: 15,
    codeSize: 6,
    decoderUnits: undefined,
    encoderAlpha: 1.61803398875,
    encoderLayers: 3,
    decoderLayers,
    encoderUnits: 0.8,
    epochs: 100,
    frameSize,
    initialEpoch: 0,
    inputSize,
    outputSize,
    logLevel: 'info',
    mdctStatsPath: undefined,
    modelPath: undefined,
    noiseAmplitude: 0.01,
    scaleIn,
    scaleOut,
    shuffle: true,
    signalIn: undefined,
    signalOut: undefined,
    trainAttempts: 1,
    trainModel: false,
    verbose: false,

  }, cfg, {
    encoderUnits,
    scaleIn,
    scaleOut,
  });
}

async function loadModel(modelPath, cfg) {
  if (modelPath == null) { return {}; }
  let modelUrl = normalizeUrl(modelPath);
  let coder;
  let savedModel;
  if (modelUrl) {
    try {
      savedModel = await tf.loadLayersModel(`${modelUrl}/model.json`);
      logger.info(`loadModel() found: ${modelUrl}`);
    } catch(e) { 
      logger.info(`loadModel() not found: ${modelUrl}`);
    }
  }
  if (savedModel) {
    let savedCfg = AutoEncoder.modelConfiguration(savedModel);
    Object.keys(savedCfg).forEach(key=>{
      if (cmdCfg.hasOwnProperty(key)) {
        let savedVal = savedCfg[key];
        let cmdVal = cmdCfg[key];
        if (savedVal !== cmdCfg[key]) {
          logger.info(`savedModel.${key}:${savedVal} overrides command option: ${cmdVal}`);
        }
      }
    });
    savedCfg.model = savedModel;
    coder = new AutoEncoder(Object.assign({}, cfg, savedCfg));
    logger.debug(`loadModel() new model`, coder);
  } else {
    coder = new AutoEncoder(cfg);
    logger.debug(`loadModel() existing model`, coder);
  }
  return {
    modelUrl,
    savedModel,
    coder,
  }
}

async function chartWorst({model, inputs, outputs, stats, chartLines}) {
  let { iMax, max, avg }  = stats;
  let xtest = tf.tensor2d(inputs.slice(iMax,iMax+1));
  let ytest = await model.predict(xtest);
  let chart = new Chart();
  chart.plot({
    data: [[...ytest.dataSync()], outputs[iMax]], 
    title:`Worst frame:${iMax} mse:${max} mseAvg:${avg} 1:expected 2:actual`,
    lines: chartLines,
  });
}

async function writeSignal(fpath, signal) {
  if (fpath.endsWith('.wav')) {
    let wav = signal.toWav();
    try {
      await fs.promises.writeFile(fpath, wav);
      logger.info(`writing signal: ${fpath} length: ${wav.length}`);
    } catch(e) {
      throw logger.error(`Could not write: ${fpath}`, e.message);
    }
  } else {
    throw logger.error('E_FILE_UNSUPPORTED', `Unsupported file type: ${fpath}`);
  }
}

async function calcMdctStats(triBks, mdctStatsPath) {
  let stats = [];
  let nCoeffs = triBks[0].length;
  for (let iCoeff = 0; iCoeff < nCoeffs; iCoeff++) {
    let c = triBks.map(tb=>tb[iCoeff]);
    let cStats = Signal.stats(c);
    cStats.coefficient = iCoeff;
    stats.push(cStats);
  }
  await fs.promises.writeFile(mdctStatsPath, JSON.stringify(stats, null, '\t'));
  return stats;
}

async function initializeScale(scale) {
  if (typeof scale === 'string' && scale.endsWith('.json')) {
    let json = JSON.parse(await fs.promises.readFile(scale));
    scale = json.map(s=>Math.max(Math.abs(s.min),Math.abs(s.max)));
    logger.info(`initializeScale() =>`, 
      scale.map(v=>Number(v.toFixed(1))).slice(0,5).join(','), '...');
  } else {
    scale = Number(scale);
    assert(!isNaN(scale), `[E_SCALE_NAN] Scale must be a number`);
    logger.info(`initializeScale() =>`, scale);
  }
  return scale;
}

(async function() {
  let cfg = await configuration(cmdCfg);
  let { 
    batchSize,
    chartLines,
    dampen=0,
    epochs, 
    frameSize,
    initialEpoch, 
    inputSize,
    logEpoch, 
    mdctStatsPath,
    modelPath, 
    noiseAmplitude,
    residualOut,
    scaleIn,
    scaleOut,
    shuffle,
    signalIn, 
    signalOut,
    threshold=0,
    trainAttempts,
    trainModel, 

  } = cfg;
  let commandResult = -1; //  not saved
  logger.info(script, argv.slice(2).join(' '));
  logger.debug(`command options parsed as`, cfg);
  let nCoeffs = frameSize/2;
  let mdct = new Mdct({frameSize});
  let wavSig = await wavSignal(signalIn);
  let { frames:outputs } = AutoEncoder.frameSignal(wavSig, 
    {frameSize, threshold, dampen, scale:scaleOut});
  let {triBks, inputs} = await mdctTriBlocks({wavSig, mdct, scaleIn});
  let nTriBks = triBks.length;
  logger.info(`tri-blocks:${triBks.length}x${triBks[0].length}`,
    `frames:${outputs.length}x${outputs[0].length}`,
    `signalIn:${signalIn}`);
  mdctStatsPath && await calcMdctStats(triBks, mdctStatsPath);
  let { coder, modelUrl, savedModel } = await loadModel(modelPath, cfg);

  let model;
  if (modelPath) {
    model = coder.model;
    model.summary();

    let valOpts = {inputs, outputs, frameSize};
    let statsCoeffsIn = await coder.validateSignal(wavSig, valOpts);

    if (trainModel) {
      let save = 0;
      for (let iTrain=1; !save && iTrain <= trainAttempts; iTrain++) {
        logger.info(`training model (attempt #${iTrain}/${trainAttempts})...`);
        let msStart = Date.now();
        let resTrained = trainModel && (await coder.train({
          batchSize,
          inputs,
          outputs, 
          shuffle,
          epochs, 
          initialEpoch, 
          noiseAmplitude,
          logEpoch,
        }));
        let msElapsed = Date.now() - msStart;
        var statsTrained = await coder.validateSignal(wavSig, valOpts);
        logger.info(`errors after training:`, statsTrained);
        await chartWorst({model, inputs, outputs, stats:statsTrained, chartLines});
        logger.debug(`errors before training`, statsCoeffsIn);
        logger.info(`current mse:`, statsCoeffsIn.avg);
        logger.info(`trained mse: ${statsTrained.avg} elapsed:${(msElapsed/1000).toFixed(2)}s`);
        if (savedModel !== model) {
          logger.info(`saving new model#${iTrain} => ${modelUrl}`);
          save = iTrain;
        } else if (statsTrained && statsTrained.avg < statsCoeffsIn.avg) {
          logger.info(`saving better model#${iTrain} => ${modelUrl}`);
          save = iTrain;
        } else {
          logger.info(`trained model not saved (mseCurrent <= mseTrained)`);
        } 
      }
      if (save) {
        await model.save(modelUrl);
        commandResult = 0;
      } else {
        logger.info(`Could not train better model after ${trainAttempts} attempts`);
      }
    } else if (modelPath) {
      logger.info(`no changes made to trained model`);
      await chartWorst({model, inputs, outputs, stats:statsCoeffsIn, chartLines});
    }
  }

  let sigOut;
  if (signalOut && coder) {
    sigOut = sigOut || coder.transform(coeffsIn, {threshold});
    let { data: coeffsOut } = sigOut;
    logger.info(`Creating signal from MDCT coefficients:`,
      `${coeffsOut.constructor.name}[${coeffsOut.length}]`);
    let window = Mdct.WINDOWS[1];
    let dataLength = coeffsOut.length; // TODO: use ACTUAL data length
    let dataOut = mdct.decode(coeffsOut, {window}).slice(0, dataLength);
    console.log(`dataOut`, dataOut.constructor.name);
    sigOut = new Signal(dataOut);
    await writeSignal(signalOut, sigOut);
  }

  if (signalOut && residualOut) {
    let { data:dataOut } = sigOut || coder.transform(coeffs);
    let dataRes = new Int16Array(dataOut.length);
    for (let i=0; i < dataOut.length; i++) {
      dataRes[i] = dataIn[i] - dataOut[i];
    }
    let sigRes = new Signal(dataRes);
    await writeSignal(residualOut, sigRes);
  }
  
  process.exit(commandResult);
})();
