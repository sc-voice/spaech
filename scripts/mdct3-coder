#!/usr/bin/env node

const fs = require('fs');
const path = require('path');
const assert = require('assert')
const { exec, execSync } = require('child_process');
const { logger } = require('log-instance');
const tf = require('@tensorflow/tfjs-node');
const { WaveFile } = require('wavefile');
const {
  Chart,
  AutoEncoder,
  Mdct,
  Signal,
} = require('../index');

const APP_DIR = path.dirname(__dirname);
const TEST_DATA_DIR = path.join(APP_DIR, 'test/data');
const EVAM_ME_SUTTAM_WAV = path.join(TEST_DATA_DIR, 'evam-me-suttam.wav');
const AN9_20_4_3_WAV = path.join(TEST_DATA_DIR, 'an9.20_4.3.wav');
const argv = process.argv;
const script = argv[1].split('/').pop();
const SOUND_END = path.join(APP_DIR, 'static/training-end.mp3');
const SOUND_SUCCESS = path.join(APP_DIR, 'static/training-success.mp3');
const SOUND_FAILURE = path.join(APP_DIR, 'static/training-failure.mp3');
const SOUND_ADJUST = path.join(APP_DIR, 'static/training-adjust.mp3');

function help() {
    console.log(`
NAME
        mdct3-coder - compress/expand MDCT tri-blocks to audio

SYNOPSIS
        mdct3-coder [OPTIONS] 
        mdct3-coder --signal-in TRAIN_WAV --model-path MODEL_PATH --train ATTEMPTS
        mdct3-coder -si TRAIN_WAV -sv VAL_WAV -mp MODEL_PATH -so XFM_VAL_WAV

DESCRIPTION
        Autoencode audio signal with an asymmetric auto-encoder (AAN). AAN input
        consists of tri-blocks of 3*frameSize/2 MDCT coefficients. AAN output
        consists of audio signal frames with a default frameSize of 192.
        The AAN relies on snake activations (https://arxiv.org/pdf/2006.08195.pdf)
        to handle the periodicity inherent in audio signals.

        The MDCT3 auto-encoder is asymmetric, with 3 inputs for every 2 outputs.  
        This 3:2 ratio characterizes the MDCT coefficient overlap
        in that it takes 3 coefficient blocks to represent a single signal frame
        that is the length of 2 coefficient blocks. The asymmetry allows
        the auto-encoder to use MDCT coefficient tri-blocks as recognizable features.
        Each tri-block has a 1-to-1 mapping to the corresponding audio frame, so
        the autoencoder is essentially still doing a 1-to-1 mapping, but from a
        pre-transformed input space.

        See scripts/train-m3 for example of use.

    -bs, --batch-size N
        Number of training examples in each batch (128)

    -cl, --chart-lines N
        Number of lines used to chart worst signal mismatch (15)

    -cs, --code-size
        Number of units in the bottleneck code layer (96)

    -dl, --decoder-layers N
        Number of decoder layers (encoderLayers)

    -du, --decoder-units N1,N2,...,NN
        Number of units in each decoder layer: (reverse of encoderUnits)

    -ea, --encoder-alpha A
    -ea, --encoder-alpha A1,A2,...,AN 
        Snake activation frequency coefficient. Either a list of alpha
        coefficients (one for each layer), or a single number. A single
        alpha number will be used to generate an alpha for each
        encoder/decoder layer. The default is the Golden Ratio. (1.61803398875)

    -el, --encoder-layers N
        Number of encoder/decoder layers (3)

    -ep, --epochs
        Training epochs (100)

    -eu, --encoder-units K
    -eu, --encoder-units N1,N2,...,NN
        Number of units in each encoder layer (0.8)
        If a single number K is given, the each successive layer will decrease
        by given factor (e.g., frameSize, K*frameSize, K*K*frameSize, ...)
        Alternatively, a list of specific unit numbers can be given.

    -ie, --initial-epoch EPOCH
        Initial epoch for continued training

    -le, --log-epoch N
        Log training stats every every N epochs (10)

    -fs, --frame-size
        Audio is encoded/decoded by consecutive frames of given size. (192)

    -?, --help
        Print help

    -ll, --log-level
        Logging level: warn, error, [info], debug

    -ms, --mdct-stats JSON_FILE
        Save MDCT coefficient stats for input signal

    -mp, --model-path MODEL_FOLDER
    -mp, --model-path URL
        JSON resource URL or local file path (test/model/coder)

    -na, --noise-amplitude  N
    -nk, --noise-amplitude-k N_THOUSANDTH
        Initial noise amplitude as a number [0..1] or a thousandth [0...999]. Noise
        amplitude is halved to lowest thousandth with each training failure (512/1000)

    -ns, --no-shuffle
        Do not shuffle training dataset (shuffle)

    -ro, --residual-out WAV_FILE
        Output residual of signal minus tranformed signal.
        
    -scm, --scale-mdct SCALE
    -scm, --scale-mdct JSON_FILE
        MDCT coefficient normalization to [-1,1] interval. (512)
        If a JSON file is given, the scale array is read from the file.
        (test/data/an9.20_4.3-mdct3-stats.json)

    -sc, --scale SCALE
        Output audio signal scale (16384)

    -si, --signal-in WAV_FILE
        Input signal

    -sv, --signal-validation WAV_FILE
        Validation signal (input signal)

    -so, --signal-out WAV_FILE
        Output file for transformed validation signal

    -tr, --train N
        Train code with up to N attempts to save a better model.
        If omitted, model is used as is without training. (0)

`);
    process.exit(0);
}

function playSound(sound) {
  let cmd = `ffplay -nodisp -autoexit -loglevel error -stats ${sound}`;
  execSync(cmd, {
    cwd: APP_DIR,
  });
}

function die(e) {
  playSound(SOUND_FAILURE);
  process.exit(-1);
}

var cmdCfg = {};

var nargs = argv.length;
if (nargs < 3) {
    help();
}
for (var i = 2; i < nargs; i++) {
  var arg = argv[i];
  let requiredArg = ()=>{
    let nextArg = argv[++i];
    if (nextArg == null) {
      die(logger.error('E_REQUIRED', `Expected additional information for: ${arg}`));
    }
    return nextArg;
  }
  let requiredNumber = ()=>{
    let n = Number(requiredArg());
    if (isNaN(n)) {
      die(logger.error(`[E_NUMBER] "${argv[i-1]}" option requires a number:${argv[i]}`));
    }
    return n;
  }
  if (i<2) { continue; }
  if (arg === '-?' || arg === '--help') {
    help();
  } else if (arg === '-du' || arg === '--decoder-units') {
    cmdCfg.decoderUnits = requiredArg().split(',').map(v=>Math.max(1, Math.round(Number(v))));
  } else if (arg === '-ea' || arg === '--encoder-alpha') {
    cmdCfg.encoderAlpha = requiredArg().split(',').map(v=>Number(v));
    if (cmdCfg.encoderAlpha.length === 1) { cmdCfg.encoderAlpha = cmdCfg.encoderAlpha[0]; }
  } else if (arg === '-le' || arg === '--log-epoch') {
    cmdCfg.logEpoch = requiredNumber();
  } else if (arg === '-dl' || arg === '--decoder-layers') {
    cmdCfg.decoderLayers = requiredNumber();
  } else if (arg === '-el' || arg === '--encoder-layers') {
    cmdCfg.encoderLayers = requiredNumber();
  } else if (arg === '-eu' || arg === '--encoder-units') {
    cmdCfg.encoderUnits = requiredArg();
  } else if (arg === '-scm' || arg === '--scale-mdct') {
    cmdCfg.scaleIn = requiredArg();
  } else if (arg === '-sc' || arg === '--scale') {
    cmdCfg.scaleOut = requiredNumber();
  } else if (arg === '-ns' || arg === '--no-shuffle') {
    cmdCfg.shuffle = false;
  } else if (arg === '-ep' || arg === '--epochs') {
    cmdCfg.epochs = requiredNumber();
  } else if (arg === '-ie' || arg === '--initial-epoch') {
    cmdCfg.initialEpoch = requiredNumber();
  } else if (arg === '-ms' || arg === '--mdct-stats') {
    cmdCfg.mdctStatsPath = requiredArg();
  } else if (arg === '-mp' || arg === '--model-path') {
    cmdCfg.modelPath = requiredArg();
  } else if (arg === '-bs' || arg === '--batch-size') {
    cmdCfg.batchSize = requiredNumber();
  } else if (arg === '-cl' || arg === '--chart-lines') {
    cmdCfg.chartLines = requiredNumber();
  } else if (arg === '-tr' || arg === '--train') {
    cmdCfg.trainAttempts = requiredNumber();
  } else if (arg === '-cs' || arg === '--code-size') {
    cmdCfg.codeSize = requiredNumber();
  } else if (arg === '-na' || arg === '--noise-amplitude') {
    cmdCfg.noiseAmplitude = requiredNumber();
  } else if (arg === '-nk' || arg === '--noise-amplitude-k') {
    cmdCfg.noiseAmplitude = requiredNumber()/1000;
  } else if (arg === '-fs' || arg === '--frame-size') {
    cmdCfg.frameSize = requiredNumber();
  } else if (arg === '-ro' || arg === '--residual-out') {
    cmdCfg.residualOut = requiredArg();
  } else if (arg === '-sv' || arg === '--signal-validation') {
    cmdCfg.signalValidation = requiredArg();
  } else if (arg === '-si' || arg === '--signal-in') {
    cmdCfg.signalIn = requiredArg();
  } else if (arg === '-so' || arg === '--signal-out') {
    cmdCfg.signalOut = requiredArg();
  } else if (arg === '-ll' || arg === '--log-level') {
    cmdCfg.logLevel = logger.logLevel = requiredArg();
  } else {
    die(logger.error('E_UNKNOWN_OPTION', `Unknown option: ${argv[i]}`));
  }
}

async function wavSignal(fpath=EVAM_ME_SUTTAM_WAV) {
  assert(fpath, `Expected signal file path`);
  let buf = await fs.promises.readFile(fpath);
  let wf = new WaveFile(buf);
  let wavSig = new Signal(wf.getSamples(false, Int16Array));
  let stats = wavSig.stats();
  logger.debug(`wavSignal`, fpath, stats);
  logger.info(`wavSignal() ${fpath} =>`, `max:`, stats.max, `count:`, stats.count);

  return wavSig;
}

async function mdctTriBlocks({wavSig, mdct, scaleIn}) {
  let { frameSize } = mdct;
  assert(wavSig, `Expected input WAV signal`);
  assert(scaleIn instanceof Array, `Expected scaleIn array`);
  let {data:sigIn} = wavSig;
  let window = Mdct.WINDOWS[1];
  let triBks = [...mdct.encodeTriBlocks(sigIn, {})];
  let maxScaled = 0;
  let inputs = triBks.map(tb=>[...tb].map((v,i)=>{
    let vScaled = v/scaleIn[i];
    if (maxScaled < vScaled) { maxScaled = vScaled }
    return vScaled;
  }));
  logger.info(`mdctTriBlocks() tri-blocks:`, triBks.length, `maxScaled:`, maxScaled); 
  return {triBks, inputs};
}

function normalizeUrl(urlOrPath) {
  if (urlOrPath == null) {
    die(logger.error('E_MODEL_PATH', `Model url or path is required: -mp PATH`));
  }
  if (/^[a-z]*:/.test(urlOrPath)) {
    return urlOrPath;
  } 

  var url = path.join(process.cwd(), urlOrPath);
  return `file:////${url}`;
}

async function configuration(cfg=cmdCfg) {
  let { 
    encoderUnits, decoderLayers, frameSize=192, 
    scaleIn=`test/data/an9.20_4.3-mdct3-stats.json`,
    scaleOut=16384,
    signalIn, signalValidation,
  } = cfg;

  signalValidation = signalValidation || signalIn;

  if (encoderUnits != null) {
    if (/,/.test(encoderUnits)) {
      encoderUnits = encoderUnits.split(',').map(v=>Math.round(Number(v)));
    } else {
      encoderUnits = Number(encoderUnits);
    }
  }

  let inputSize = frameSize * 3 / 2;
  let outputSize = frameSize;
  scaleIn = await initializeScale(scaleIn, inputSize);

  return Object.assign({}, {
    batchSize: 128,
    chartLines: 15,
    codeSize: 96,
    decoderUnits: undefined,
    encoderAlpha: 1.61803398875,
    encoderLayers: 3,
    decoderLayers,
    encoderUnits: 0.8,
    epochs: 100,
    frameSize,
    initialEpoch: 0,
    inputSize,
    outputSize,
    logLevel: 'info',
    mdctStatsPath: undefined,
    modelPath: undefined,
    noiseAmplitude: 512/1000,
    scaleIn,
    scaleOut,
    shuffle: true,
    signalIn: undefined,
    signalOut: undefined,
    trainAttempts: 0,
    verbose: false,

  }, cfg, {
    encoderUnits,
    scaleIn,
    scaleOut,
    signalValidation,
  });
}

async function loadModel(modelPath, cfg) {
  if (modelPath == null) { return {}; }
  let modelUrl = normalizeUrl(modelPath);
  let coder;
  let savedModel;
  if (modelUrl) {
    try {
      savedModel = await tf.loadLayersModel(`${modelUrl}/model.json`);
      logger.info(`loadModel() found: ${modelUrl}`);
    } catch(e) { 
      logger.info(`loadModel() not found: ${modelUrl}`);
    }
  }
  if (savedModel) {
    let savedCfg = AutoEncoder.modelConfiguration(savedModel);
    Object.keys(savedCfg).forEach(key=>{
      if (cmdCfg.hasOwnProperty(key)) {
        let savedVal = savedCfg[key];
        let cmdVal = cmdCfg[key];
        if (savedVal !== cmdCfg[key]) {
          logger.info(`savedModel.${key}:`, savedVal, `overrides command option:`, cmdVal);
        }
      }
    });
    savedCfg.model = savedModel;
    coder = new AutoEncoder(Object.assign({}, cfg, savedCfg));
    logger.debug(`loadModel() new model`, coder);
  } else {
    coder = new AutoEncoder(cfg);
    logger.debug(`loadModel() existing model`, coder);
  }
  return {
    modelUrl,
    savedModel,
    coder,
  }
}

function assertNumbers(inputs, msg) {
  inputs.forEach((input,i)=> {
    if (typeof input === 'number') {
      assert(!isNaN(input), `${msg}[${i}]:${input}`);
    } else {
      let nans = input.reduce(((a,v)=> isNaN(v) ? a+1 : a), 0);
      assert(!nans, `${msg}[${i}] has NaNs:`+
        [...input].map(v=>isNaN(v)?'N':'.').join(''));
    }
  });
}

async function chartWorst({model, inputs, outputs, stats, chartLines}) {
  let { iMax, max, avg }  = stats;
  assertNumbers(inputs, `[E_CHART_NAN] inputs`);
  let xtest = tf.tensor2d(inputs.slice(iMax,iMax+1));
  let ytest = await model.predict(xtest);
  let chart = new Chart();
  chart.plot({
    data: [[...ytest.dataSync()], outputs[iMax]], 
    title:`Worst frame:${iMax} mse:${max} mseAvg:${avg} 1:expected 2:actual`,
    lines: chartLines,
  });
}

async function writeSignal(fpath, signal) {
  if (fpath.endsWith('.wav')) {
    let wav = signal.toWav();
    try {
      await fs.promises.writeFile(fpath, wav);
      logger.info(`writing signal: ${fpath} length: ${wav.length}`);
    } catch(e) {
      die(logger.error(`Could not write: ${fpath}`, e.message));
    }
  } else {
    die(logger.error('E_FILE_UNSUPPORTED', `Unsupported file type: ${fpath}`));
  }
}

async function calcMdctStats(triBks, mdctStatsPath) {
  let stats = [];
  let nCoeffs = triBks[0].length;
  for (let iCoeff = 0; iCoeff < nCoeffs; iCoeff++) {
    let c = triBks.map(tb=>tb[iCoeff]);
    let cStats = Signal.stats(c);
    cStats.coefficient = iCoeff;
    stats.push(cStats);
  }
  await fs.promises.writeFile(mdctStatsPath, JSON.stringify(stats, null, '\t'));
  return stats;
}

async function initializeScale(scale, inputSize) {
  if (typeof scale === 'string' && scale.endsWith('.json')) {
    let json = JSON.parse(await fs.promises.readFile(scale));
    scale = json.map(s=>Math.max(Math.abs(s.min),Math.abs(s.max)));
    logger.info(`initializeScale() =>`, 
      scale.map(v=>Number(v.toFixed(1))).slice(0,8).join(', '), '...');
    assertNumbers(scale, `[E_SCALE_NAN] scale`);
    assert(scale.length === inputSize, 
      `[E_SCALE_SIZE] scale.length expected:${inputSize} actual:${scale.length}`);
  } else {
    scale = Number(scale);
    assert(!isNaN(scale), `[E_SCALE_NAN] Scale must be a number`);
    logger.info(`initializeScale() =>`, scale);
  }
  return scale;
}

async function train({modelUrl, statsCurrent, iTrain, coder, valOpts, 
  noiseAmplitude, inputs, outputs, savedModel, cfg}) {
  try {
    let { 
      batchSize, 
      chartLines, 
      epochs, 
      initialEpoch,
      logEpoch,
      shuffle, 
      trainAttempts,
    } = cfg;
    let { model } = coder;
    logger.info(`training model (attempt #${iTrain}/${trainAttempts})...`);
    let msStart = Date.now();
    let save = 0;
    let resTrained = await coder.train({
      batchSize,
      epochs, 
      initialEpoch, 
      inputs,
      logEpoch,
      noiseAmplitude,
      outputs, 
      shuffle,
    });
    let elapsed = Number(((Date.now() - msStart)/1000).toFixed(2));
    var statsTrained = await coder.validateSignal(null, valOpts);
    logger.debug(`errors after training:`, statsTrained);
    await chartWorst({model, inputs, outputs, stats:statsTrained, chartLines});
    logger.info(`current mse:`, statsCurrent.avg);
    logger.info(`trained mse:`, statsTrained.avg, `elapsed:`, elapsed );
    if (savedModel !== model) {
      logger.info(`saving new model#${iTrain} => ${modelUrl}`);
      save = iTrain;
    } else if (statsTrained && statsTrained.avg < statsCurrent.avg) {
      logger.info(`saving better model#${iTrain} => ${modelUrl}`);
      save = iTrain;
    } else {
      logger.info(`trained model not saved (mseCurrent <= mseTrained)`);
      if (noiseAmplitude) {
        let oldAmplitude = noiseAmplitude;
        noiseAmplitude = Math.floor(1000*noiseAmplitude/2)/1000;
        logger.info(`reducing noiseAmplitude:${oldAmplitude} => ${noiseAmplitude}`);
        playSound(SOUND_ADJUST);
      }
    } 
    return {
      save,
      statsTrained,
      noiseAmplitude,
    }
  } catch(e) {
    die(logger.error(`[E_TRAIN]`, e.message));
  }
}

async function writeValidationSignal({inputsVal, scaleOut, coder, signalOut}) {
  let predicted = (await coder.predict(inputsVal));
  let scaled = new Int16Array(scaleOut instanceof Array 
    ? predicted.map((v,i)=>v*scaleOut[i])
    : predicted.map((v)=>v*scaleOut));
  let sigOut = new Signal(scaled);
  await writeSignal(signalOut, sigOut);
  playSound(signalOut);

  return {
    sigOut,
  }
}

(async function() {
  let cfg = await configuration(cmdCfg);
  let { 
    batchSize,
    chartLines,
    dampen=0,
    epochs, 
    frameSize,
    initialEpoch, 
    inputSize,
    logEpoch, 
    mdctStatsPath,
    modelPath, 
    noiseAmplitude,
    residualOut,
    scaleIn,
    scaleOut,
    shuffle,
    signalIn, 
    signalOut,
    signalValidation,
    threshold=0,
    trainAttempts,

  } = cfg;
  logger.info(script, argv.slice(2).join(' '));
  logger.debug(`command options parsed as`, cfg);
  let nCoeffs = frameSize/2;
  let mdct = new Mdct({frameSize});
  let frameOpts = {frameSize, threshold, dampen, scale:scaleOut};
  let trainSig = await wavSignal(signalIn);
  let valSig = signalIn === signalValidation
    ? trainSig
    : (await wavSignal(signalValidation));
  let outputs = AutoEncoder.frameSignal(trainSig, frameOpts).frames;
  let outputsVal = signalIn === signalValidation
    ? outputs
    : AutoEncoder.frameSignal(valSig, frameOpts).frames;
  let mdctTrain = await mdctTriBlocks({wavSig: trainSig, mdct, scaleIn});
  let {triBks, inputs} = mdctTrain;
  assertNumbers(inputs, `[E_MDCTTRAIN_NAN] inputs`);
  let mdctVal = signalIn === signalValidation
    ? mdctTrain
    : (await mdctTriBlocks({wavSig: valSig, mdct, scaleIn}));
  let { inputs: inputsVal } = mdctVal;
  assertNumbers(inputsVal, `[E_MDCTVAL_NAN] inputsVal`);
  logger.info(`tri-blocks:${triBks.length}x${triBks[0].length}`,
    `frames:${outputs.length}x${outputs[0].length}`,
    `signalIn:${signalIn}`);
  mdctStatsPath && await calcMdctStats(triBks, mdctStatsPath);
  let { coder, modelUrl, savedModel } = await loadModel(modelPath, cfg);

  let model;
  assert(modelPath, `[E_MODEL_PATH] modelPath is required`);
  model = coder.model;

  let valOpts = {inputs:inputsVal, outputs:outputsVal, frameSize};
  let statsCurrent = await coder.validateSignal(valSig, valOpts);
  let sigOut;

  if (trainAttempts) {
    model.summary();
    let noise = noiseAmplitude;
    for (let iTrain=1; iTrain <= trainAttempts; iTrain++) {
      do {
        let res = await train({modelUrl, statsCurrent, iTrain, coder, valOpts, 
          noiseAmplitude:noise, inputs, outputs, savedModel, cfg,
        });
        if (res.save) {
          await model.save(modelUrl);
          playSound(SOUND_SUCCESS);
          signalOut && await writeValidationSignal({inputsVal, scaleOut, coder, signalOut});
          statsCurrent = res.statsTrained;
          savedModel = model;
        } else {
          if (noise) {
            noise = res.noiseAmplitude;
          } else {
            die(logger.error(`Could not train better model after ${trainAttempts} attempts`));
          }
        }
      } while (noise);
    }
  } else if (modelPath) {
    signalOut && await writeValidationSignal({inputsVal, scaleOut, coder, signalOut});
    logger.debug(`signal stats for existing model`, statsCurrent);
    await chartWorst({model, inputs: inputsVal, outputs: outputsVal, 
      stats:statsCurrent, chartLines});
  }

  if (signalOut && residualOut) {
    let { data:dataOut } = sigOut || coder.transform(coeffs);
    let dataRes = new Int16Array(dataOut.length);
    for (let i=0; i < dataOut.length; i++) {
      dataRes[i] = dataIn[i] - dataOut[i];
    }
    let sigRes = new Signal(dataRes);
    await writeSignal(residualOut, sigRes);
  }
  
  playSound(SOUND_END);
  process.exit(0);
})();
