#!/usr/bin/env node

const fs = require('fs');
const path = require('path');
const assert = require('assert')
const { exec, execSync } = require('child_process');
const { logger } = require('log-instance');
const tf = require('@tensorflow/tfjs-node');
const { WaveFile } = require('wavefile');
const {
  Chart,
  AutoEncoder,
  Signal,
} = require('../index');

const APP_DIR = path.dirname(__dirname);
const TEST_DATA_DIR = path.join(APP_DIR, 'test/data');
const EVAM_ME_SUTTAM_WAV = path.join(TEST_DATA_DIR, 'evam-me-suttam.wav');
const AN9_20_4_3_WAV = path.join(TEST_DATA_DIR, 'an9.20_4.3.wav');
const argv = process.argv;
const script = argv[1].split('/').pop();
const SOUND_END = path.join(APP_DIR, 'static/training-end.mp3');
const SOUND_SUCCESS = path.join(APP_DIR, 'static/training-success.mp3');
const SOUND_FAILURE = path.join(APP_DIR, 'static/training-failure.mp3');
const SOUND_ADJUST = path.join(APP_DIR, 'static/training-adjust.mp3');

function help() {
    console.log(`
NAME
        wav2-coder - audio 2:1 auto-encoder

SYNOPSIS
        wav2-coder [OPTIONS] 
        wav2-coder -si INPUT_WAV -se EXPECT_WAV -mp MODEL_PATH -tr ATTEMPTS
        wav2-coder -si INPUT_WAV -mp MODEL_PATH -so XFM_INPUT_WAV

DESCRIPTION
        Audio auto-encoder generates 1 output frame for 2 consecutive input frames

        See scripts/train-w2 for example of use.

    -bs, --batch-size N
        Number of training examples in each batch (128)

    -cl, --chart-lines N
        Number of lines used to chart worst signal mismatch (15)

    -cs, --code-size
        Number of units in the bottleneck code layer (96)

    -dl, --decoder-layers N
        Number of decoder layers (encoderLayers)

    -du, --decoder-units N1,N2,...,NN
        Number of units in each decoder layer: (reverse of encoderUnits)

    -ea, --encoder-alpha A
    -ea, --encoder-alpha A1,A2,...,AN 
        Snake activation frequency coefficient. Either a list of alpha
        coefficients (one for each layer), or a single number. A single
        alpha number will be used to generate an alpha for each
        encoder/decoder layer. The default is the Golden Ratio. (1.61803398875)

    -el, --encoder-layers N
        Number of encoder/decoder layers (3)

    -ep, --epochs
        Training epochs (100)

    -eu, --encoder-units K
    -eu, --encoder-units N1,N2,...,NN
        Number of units in each encoder layer (0.9)
        If a single number K is given, the each successive layer will decrease
        by given factor (e.g., inputSize, K*inputSize, K*K*inputSize, ...)
        Alternatively, a list of specific unit numbers can be given.

    -ie, --initial-epoch EPOCH
        Initial epoch for continued training

    -le, --log-epoch N
        Log training stats every every N epochs (10)

    -fs, --frame-size
        Audio is encoded/decoded by consecutive frames of given size. (192)

    -?, --help
        Print help

    -ll, --log-level
        Logging level: warn, error, [info], debug

    -mp, --model-path MODEL_FOLDER
    -mp, --model-path URL
        JSON resource URL or local file path (test/model/coder)

    -na, --noise-amplitude  N
    -nk, --noise-amplitude-k N_THOUSANDTH
        Initial noise amplitude as a number [0..1] or a thousandth [0...999]. Noise
        amplitude is halved to lowest thousandth with each training failure (512/1000)

    -ns, --no-shuffle
        Do not shuffle training dataset (shuffle)

    -sc, --scale SCALE
        Output audio signal scale (16384)

    -si, --signal-in WAV_FILE
        Input signal 

    -se, --signal-expected WAV_FILE
        Expected outputs signal for training (input signal)

    -sv, --signal-validation WAV_FILE
        Validation input signal (input signal)

    -sve, --signal-validation-expected WAV_FILE
        Validation expected output signal (validation input signal)

    -so, --signal-out WAV_FILE
        Output file for transformed validation signal

    -tr, --train N
        Train code with up to N attempts to save a better model.
        If omitted, model is used as is without training. (0)

    -wf, --wav-frames N
        Number of WAV frames to use as input (2)

`);
    process.exit(0);
}

function playSound(sound) {
  let cmd = `ffplay -nodisp -autoexit -loglevel error -stats ${sound}`;
  execSync(cmd, {
    cwd: APP_DIR,
  });
}

function die(e) {
  playSound(SOUND_FAILURE);
  process.exit(-1);
}

var cmdCfg = {};

var nargs = argv.length;
if (nargs < 3) {
    help();
}
for (var i = 2; i < nargs; i++) {
  var arg = argv[i];
  let requiredArg = ()=>{
    let nextArg = argv[++i];
    if (nextArg == null) {
      die(logger.error('E_REQUIRED', `Expected additional information for: ${arg}`));
    }
    return nextArg;
  }
  let requiredNumber = ()=>{
    let n = Number(requiredArg());
    if (isNaN(n)) {
      die(logger.error(`[E_NUMBER] "${argv[i-1]}" option requires a number:${argv[i]}`));
    }
    return n;
  }
  if (i<2) { continue; }
  if (arg === '-?' || arg === '--help') {
    help();
  } else if (arg === '-du' || arg === '--decoder-units') {
    cmdCfg.decoderUnits = requiredArg().split(',').map(v=>Math.max(1, Math.round(Number(v))));
  } else if (arg === '-ea' || arg === '--encoder-alpha') {
    cmdCfg.encoderAlpha = requiredArg().split(',').map(v=>Number(v));
    if (cmdCfg.encoderAlpha.length === 1) { cmdCfg.encoderAlpha = cmdCfg.encoderAlpha[0]; }
  } else if (arg === '-le' || arg === '--log-epoch') {
    cmdCfg.logEpoch = requiredNumber();
  } else if (arg === '-dl' || arg === '--decoder-layers') {
    cmdCfg.decoderLayers = requiredNumber();
  } else if (arg === '-el' || arg === '--encoder-layers') {
    cmdCfg.encoderLayers = requiredNumber();
  } else if (arg === '-eu' || arg === '--encoder-units') {
    cmdCfg.encoderUnits = requiredArg();
  } else if (arg === '-sc' || arg === '--scale') {
    cmdCfg.scaleOut = requiredNumber();
  } else if (arg === '-ns' || arg === '--no-shuffle') {
    cmdCfg.shuffle = false;
  } else if (arg === '-ep' || arg === '--epochs') {
    cmdCfg.epochs = requiredNumber();
  } else if (arg === '-ie' || arg === '--initial-epoch') {
    cmdCfg.initialEpoch = requiredNumber();
  } else if (arg === '-mp' || arg === '--model-path') {
    cmdCfg.modelPath = requiredArg();
  } else if (arg === '-bs' || arg === '--batch-size') {
    cmdCfg.batchSize = requiredNumber();
  } else if (arg === '-cl' || arg === '--chart-lines') {
    cmdCfg.chartLines = requiredNumber();
  } else if (arg === '-tr' || arg === '--train') {
    cmdCfg.trainAttempts = requiredNumber();
  } else if (arg === '-cs' || arg === '--code-size') {
    cmdCfg.codeSize = requiredNumber();
  } else if (arg === '-na' || arg === '--noise-amplitude') {
    cmdCfg.noiseAmplitude = requiredNumber();
  } else if (arg === '-nk' || arg === '--noise-amplitude-k') {
    cmdCfg.noiseAmplitude = requiredNumber()/1000;
  } else if (arg === '-fs' || arg === '--frame-size') {
    cmdCfg.frameSize = requiredNumber();
  } else if (arg === '-sv' || arg === '--signal-validation') {
    cmdCfg.signalValidation = requiredArg();
  } else if (arg === '-sve' || arg === '--signal-validation-expected') {
    cmdCfg.signalValidationExpected = requiredArg();
  } else if (arg === '-se' || arg === '--signal-expected') {
    cmdCfg.signalExpected = requiredArg();
  } else if (arg === '-si' || arg === '--signal-in') {
    cmdCfg.signalIn = requiredArg();
  } else if (arg === '-so' || arg === '--signal-out') {
    cmdCfg.signalOut = requiredArg();
  } else if (arg === '-ll' || arg === '--log-level') {
    cmdCfg.logLevel = logger.logLevel = requiredArg();
  } else if (arg === '-wf' || arg === '--wav-frames') {
    cmdCfg.wavFrames = requiredNumber();
  } else {
    die(logger.error('E_UNKNOWN_OPTION', `Unknown option: ${argv[i]}`));
  }
}

async function wavSignal(fpath=EVAM_ME_SUTTAM_WAV) {
  assert(fpath, `Expected signal file path`);
  let buf = await fs.promises.readFile(fpath);
  let wf = new WaveFile(buf);
  let wavSig = new Signal(wf.getSamples(false, Int16Array));
  let stats = wavSig.stats();
  logger.debug(`wavSignal`, fpath, stats);
  logger.info(`wavSignal() ${fpath} =>`, `max:`, stats.max, `count:`, stats.count);

  return wavSig;
}

function normalizeUrl(urlOrPath) {
  if (urlOrPath == null) {
    die(logger.error('E_MODEL_PATH', `Model url or path is required: -mp PATH`));
  }
  if (/^[a-z]*:/.test(urlOrPath)) {
    return urlOrPath;
  } 

  var url = path.join(process.cwd(), urlOrPath);
  return `file:////${url}`;
}

async function configuration(cfg=cmdCfg) {
  let { 
    encoderUnits, decoderLayers, frameSize=192, 
    scaleIn=16384, scaleOut=16384,
    signalExpected, signalIn, signalValidation, signalValidationExpected,
    inputSize,
    wavFrames=1,
  } = cfg;

  signalValidation = signalValidation || signalIn;
  signalValidationExpected = signalValidationExpected || signalValidation;
  signalExpected = signalExpected || signalIn;

  if (encoderUnits != null) {
    if (/,/.test(encoderUnits)) {
      encoderUnits = encoderUnits.split(',').map(v=>Math.round(Number(v)));
    } else {
      encoderUnits = Number(encoderUnits);
    }
  }

  assert(!isNaN(frameSize), `[E_FRAMESIZE] expected number:${frameSize}`);
  assert(!isNaN(wavFrames), `[E_WAVFRAMES] expected number:${wavFrames}`);
  inputSize = inputSize || wavFrames*frameSize;
  assert(!isNaN(inputSize), `[E_INPUTSIZE] expected number:${inputSize}`);
  let outputSize = frameSize;
  scaleIn = await initializeScale(scaleIn, inputSize);

  return Object.assign({}, {
    batchSize: 128,
    chartLines: 15,
    codeSize: 96,
    decoderUnits: undefined,
    encoderAlpha: 1.61803398875,
    encoderLayers: 3,
    decoderLayers,
    encoderUnits: 0.9,
    epochs: 100,
    frameSize,
    initialEpoch: 0,
    inputSize,
    outputSize,
    logLevel: 'info',
    modelPath: undefined,
    noiseAmplitude: 512/1000,
    scaleIn,
    scaleOut,
    shuffle: true,
    signalIn: undefined,
    signalOut: undefined,
    trainAttempts: 0,
    verbose: false,
    wavFrames: 2,

  }, cfg, {
    encoderUnits,
    scaleIn,
    scaleOut,
    signalValidation,
    signalValidationExpected,
    signalExpected,
  });
}

async function loadModel(modelPath, cfg) {
  if (modelPath == null) { return {}; }
  let modelUrl = normalizeUrl(modelPath);
  let coder;
  let savedModel;
  if (modelUrl) {
    try {
      savedModel = await tf.loadLayersModel(`${modelUrl}/model.json`);
      logger.info(`loadModel() found: ${modelUrl}`);
    } catch(e) { 
      logger.info(`loadModel() not found: ${modelUrl}`);
    }
  }
  if (savedModel) {
    let savedCfg = AutoEncoder.modelConfiguration(savedModel);
    Object.keys(savedCfg).forEach(key=>{
      if (cmdCfg.hasOwnProperty(key)) {
        let savedVal = savedCfg[key];
        let cmdVal = cmdCfg[key];
        if (savedVal !== cmdCfg[key]) {
          logger.info(`savedModel.${key}:`, savedVal, `overrides command option:`, cmdVal);
        }
      }
    });
    savedCfg.model = savedModel;
    coder = new AutoEncoder(Object.assign({}, cfg, savedCfg));
    logger.debug(`loadModel() new model`, coder);
  } else {
    coder = new AutoEncoder(cfg);
    logger.debug(`loadModel() existing model`, coder);
  }
  return {
    modelUrl,
    savedModel,
    coder,
  }
}

function assertNumbers(inputs, msg) {
  inputs.forEach((input,i)=> {
    if (typeof input === 'number') {
      assert(!isNaN(input), `${msg}[${i}]:${input}`);
    } else {
      let nans = input.reduce(((a,v)=> isNaN(v) ? a+1 : a), 0);
      assert(!nans, `${msg}[${i}] has NaNs:`+
        [...input].map(v=>isNaN(v)?'N':'.').join(''));
    }
  });
}

async function chartWorst({model, inputs, outputs, stats, chartLines}) {
  let { iMax, max, avg }  = stats;
  assertNumbers(inputs, `[E_CHART_NAN] inputs`);
  let xtest = tf.tensor2d(inputs.slice(iMax,iMax+1));
  let ytest = await model.predict(xtest);
  let chart = new Chart();
  chart.plot({
    data: [[...ytest.dataSync()], outputs[iMax]], 
    title:`Worst frame:${iMax} mse:${max.toExponential(8)} mseAvg:${avg.toExponential(8)} 1:expected 2:actual`,
    lines: chartLines,
  });
}

async function writeSignal(fpath, signal) {
  if (fpath.endsWith('.wav')) {
    let wav = signal.toWav();
    try {
      await fs.promises.writeFile(fpath, wav);
      logger.info(`writing signal: ${fpath} length: ${wav.length}`);
    } catch(e) {
      die(logger.error(`Could not write: ${fpath}`, e.message));
    }
  } else {
    die(logger.error('E_FILE_UNSUPPORTED', `Unsupported file type: ${fpath}`));
  }
}

async function initializeScale(scale, inputSize) {
  if (typeof scale === 'string' && scale.endsWith('.json')) {
    let json = JSON.parse(await fs.promises.readFile(scale));
    scale = json.map(s=>Math.max(Math.abs(s.min),Math.abs(s.max)));
    logger.info(`initializeScale() =>`, 
      scale.map(v=>Number(v.toFixed(1))).slice(0,8).join(', '), '...');
    assertNumbers(scale, `[E_SCALE_NAN] scale`);
    assert(scale.length === inputSize, 
      `[E_SCALE_SIZE] scale.length expected:${inputSize} actual:${scale.length}`);
  } else {
    scale = Number(scale);
    assert(!isNaN(scale), `[E_SCALE_NAN] Scale must be a number`);
    logger.info(`initializeScale() =>`, scale);
  }
  return scale;
}

async function train({statsCurrent, iTrain, coder, valOpts, 
  noiseAmplitude, inputs, outputs, savedModel, cfg}) {
  let line = 0;
  try {
    let { 
      batchSize, 
      chartLines, 
      epochs, 
      initialEpoch,
      logEpoch,
      shuffle, 
      trainAttempts,
    } = cfg;
    let { model } = coder;
    logger.info(`training model (attempt #${iTrain}/${trainAttempts})...`);
    assert(inputs.length == outputs.length, 
      `[E_INPUTS_OUTPUTS] inputs:${inputs.length} outputs:${outputs.length}`);
    let msStart = Date.now();
    let save = 0;
    line++;
    let resTrained = await coder.train({
      batchSize,
      epochs, 
      initialEpoch, 
      inputs,
      logEpoch,
      noiseAmplitude,
      outputs, 
      shuffle,
    });
    line++;
    let elapsed = Number(((Date.now() - msStart)/1000).toFixed(2));
    var statsTrained = await coder.validateSignal(null, valOpts);
    logger.debug(`errors after training:`, statsTrained);
    await chartWorst({model, inputs, outputs, stats:statsTrained, chartLines});
    logger.info(`current mse:`, statsCurrent.avg.toExponential(8));
    let avgTrained = statsTrained.avg.toExponential(8);
    logger.info(`trained mse:`, avgTrained, `elapsed:`, elapsed );
    if (savedModel !== model) {
      logger.info(`saving new model#${iTrain} mse:`, avgTrained, `noise:`, noiseAmplitude);
      save = iTrain;
    } else if (statsTrained && statsTrained.avg < statsCurrent.avg) {
      logger.info(`saving better model#${iTrain} mse:`, avgTrained, `noise:`, noiseAmplitude);
      save = iTrain;
    } else {
      logger.info(`trained model not saved (mseCurrent <= mseTrained)`);
      if (noiseAmplitude) {
        let oldAmplitude = noiseAmplitude;
        noiseAmplitude = Math.floor(1000*noiseAmplitude/2)/1000;
        logger.info(`reducing noiseAmplitude:${oldAmplitude} => ${noiseAmplitude}`);
        playSound(SOUND_ADJUST);
      }
    } 
    return {
      save,
      statsTrained,
      noiseAmplitude,
    }
  } catch(e) {
    die(logger.error(`[E_TRAIN_${line}]`, e.message));
  }
}

async function writeValidationSignal({inputsVal, scaleOut, coder, signalOut}) {
  let predicted = (await coder.predict(inputsVal));
  let scaled = new Int16Array(scaleOut instanceof Array 
    ? predicted.map((v,i)=>v*scaleOut[i])
    : predicted.map((v)=>v*scaleOut));
  let sigOut = new Signal(scaled);
  await writeSignal(signalOut, sigOut);
  playSound(signalOut);

  return {
    sigOut,
  }
}

function inputsOfFrames(frames, inputSize) {
  let frameSize = frames[0].length;
  let wavFrames = Math.ceil(inputSize / frameSize);
  let iEnd = frames.length - 1;
  let inputs = frames.map((f,i) => {
    let inputRow = [];
    for (let j=i; j < i+wavFrames; j++) {
      let fj = frames[j] || new Float32Array(frameSize);
      inputRow = inputRow.concat([...fj]);
    }
    return inputRow;
  });
  return inputs;
}

(async function() {
  let cfg = await configuration(cmdCfg);
  let { 
    batchSize,
    chartLines,
    dampen=0,
    epochs, 
    frameSize,
    initialEpoch, 
    inputSize,
    outputSize,
    logEpoch, 
    modelPath, 
    noiseAmplitude,
    scaleIn,
    scaleOut,
    shuffle,
    signalIn, 
    signalExpected,
    signalOut,
    signalValidation,
    signalValidationExpected,
    threshold=0,
    trainAttempts,

  } = cfg;
  logger.info(script, argv.slice(2).join(' '));
  logger.debug(`command options parsed as`, cfg);
  let frameOpts = {frameSize, threshold, dampen, scale:scaleOut};
  let trainSig = await wavSignal(signalIn);
  let expSig = signalIn === signalExpected
    ? trainSig
    : await wavSignal(signalExpected);
  let valSig = signalIn === signalValidation
    ? trainSig
    : (await wavSignal(signalValidation));
  let valExpSig = signalValidation === signalValidationExpected
    ? valSig
    : (await wavSignal(signalValidationExpected));
  let inputFrames = AutoEncoder.frameSignal(trainSig, frameOpts).frames;
  let valFrames = signalIn === signalValidation
    ? inputFrames
    : AutoEncoder.frameSignal(valSig, frameOpts).frames;
  let inputs = inputsOfFrames(inputFrames, inputSize);
  assertNumbers(inputs, `[E_NAN] inputs`);
  let inputsVal = signalIn === signalValidation
    ? inputs
    : inputsOfFrames(valFrames, inputSize);
  assertNumbers(inputsVal, `[E_NAN] inputsVal`);
  let outputs = signalIn === signalExpected
    ? inputFrames
    : AutoEncoder.frameSignal(expSig, frameOpts).frames;
  let outputsVal = signalIn === signalValidationExpected
    ? outputs
    : AutoEncoder.frameSignal(valExpSig, frameOpts).frames;
  logger.info(`frames:`, outputs.length, 'x', outputs[0].length, `signalIn:${signalIn}`);
  let { coder, modelUrl, savedModel } = await loadModel(modelPath, cfg);

  let model;
  assert(modelPath, `[E_MODEL_PATH] modelPath is required`);
  model = coder.model;

  let valOpts = {inputs:inputsVal, outputs:outputsVal, frameSize};
  let statsCurrent = await coder.validateSignal(valSig, valOpts);
  let sigOut;

  if (trainAttempts) {
    model.summary();
    let noise = noiseAmplitude;
    for (let iTrain=1; iTrain <= trainAttempts; iTrain++) {
      do {
        assert(inputs[0].length === inputSize, 
          `[E_INPUTSIZE] expected:${inputSize} actual:${inputs[0].length}`);
        assert(outputs[0].length === outputSize, 
          `[E_OUTPUTSIZE] expected:${outputSize} actual:${outputs[0].length}`);
        let res = await train({modelUrl, statsCurrent, iTrain, coder, valOpts, 
          noiseAmplitude:noise, inputs, outputs, savedModel, cfg,
        });
        if (res.save) {
          await model.save(modelUrl);
          logger.debug(`saved model#${iTrain} => ${modelUrl}`);
          logger.info(`saved model#${iTrain} => ${modelPath}`);
          playSound(SOUND_SUCCESS);
          signalOut && await writeValidationSignal({inputsVal, scaleOut, coder, signalOut});
          statsCurrent = res.statsTrained;
          savedModel = model;
        } else if (noise) {
          noise = res.noiseAmplitude;
        } else {
          logger.info(`Attempt#${iTrain}/${trainAttempts}: Could not train better model`);
        }
      } while (noise);
    }
  } else if (modelPath) {
    signalOut && await writeValidationSignal({inputsVal, scaleOut, coder, signalOut});
    logger.debug(`signal stats for existing model`, statsCurrent);
    await chartWorst({model, inputs: inputsVal, outputs: outputsVal, 
      stats:statsCurrent, chartLines});
  }

  signalOut && logger.info(`final mse:${statsCurrent.avg.toExponential(8)} => ${signalOut}`);
  playSound(SOUND_END);
  process.exit(0);
})();
